# Emotion Classification for Social Media Images

A deep learning system that classifies emotions in social media images and suggests appropriate emoji reactions. Built with PyTorch, FastAPI, and modern ML practices.

## ğŸ¯ Overview

This system addresses the problem of inappropriate emoji reactions on social media by:

1. **Analyzing** images using deep learning to detect emotions
2. **Classifying** into 8 discrete emotions (happy, sad, angry, fear, surprise, disgust, neutral, other)
3. **Filtering** emoji reactions - only showing emotionally appropriate ones

## ğŸ—ï¸ Architecture

### Step A: Image â†’ Emotion Prediction

- **Backbone**: Vision Transformer (ViT) / ResNet50 / EfficientNet
- **Head**: Classification layer with dropout
- **Output**: Multi-label emotion probabilities (BCEWithLogitsLoss)

### Step B: Emotion â†’ Emoji Mapping

- Business rules mapping emotions to allowed/blocked emojis
- Configurable threshold-based filtering
- Union of allowed emojis for multiple detected emotions

## ğŸ“Š Supported Emotions

| Emotion  | Allowed Emojis       | Blocked Emojis      |
| -------- | -------------------- | ------------------- |
| Happy    | ğŸ˜€ ğŸ˜„ ğŸ˜ ğŸ˜‚ â¤ï¸ ğŸ‘ ğŸ‰ | ğŸ˜¢ ğŸ˜­ ğŸ˜¡ ğŸ˜¤         |
| Sad      | ğŸ˜¢ ğŸ˜­ ğŸ’” ğŸ¤ ğŸ™       | ğŸ˜‚ ğŸ˜† ğŸ˜ ğŸ‰         |
| Angry    | ğŸ˜¡ ğŸ˜¤ ğŸ’¢ ğŸ‘          | ğŸ˜‚ ğŸ˜† ğŸ˜            |
| Fear     | ğŸ˜¨ ğŸ˜° ğŸ˜± ğŸ™          | ğŸ˜† ğŸ˜ ğŸ‰            |
| Disgust  | ğŸ¤¢ ğŸ˜’ ğŸ™„             | ğŸ˜ ğŸ˜˜ ğŸ¥°            |
| Surprise | ğŸ˜® ğŸ¤¯ ğŸ˜² ğŸ˜³          | (context-dependent) |
| Neutral  | ğŸ‘ ğŸ™‚ ğŸ¤ ğŸ‘Œ          | ğŸ˜­ ğŸ¤¯ ğŸ˜¡            |
| Other    | ğŸ¤” ğŸ˜• ğŸ˜¬ ğŸ¤·          | -                   |

## ğŸ“ Project Structure

```
emotion-classification/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/           # Configuration files
â”‚   â”‚   â”œâ”€â”€ emotion_config.py    # Emotion-emoji mappings
â”‚   â”‚   â”œâ”€â”€ model_config.py      # Model architecture settings
â”‚   â”‚   â””â”€â”€ training_config.py   # Training hyperparameters
â”‚   â”œâ”€â”€ data/             # Data handling
â”‚   â”‚   â”œâ”€â”€ dataset.py           # PyTorch datasets
â”‚   â”‚   â”œâ”€â”€ transforms.py        # Image transformations
â”‚   â”‚   â””â”€â”€ dataloader.py        # DataLoader utilities
â”‚   â”œâ”€â”€ models/           # Model architecture
â”‚   â”‚   â”œâ”€â”€ backbone.py          # Backbone creation (timm)
â”‚   â”‚   â””â”€â”€ emotion_classifier.py # Main model class
â”‚   â”œâ”€â”€ training/         # Training pipeline
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Training loop
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Evaluation metrics
â”‚   â”‚   â””â”€â”€ loss.py              # Loss functions
â”‚   â”œâ”€â”€ inference/        # Inference pipeline
â”‚   â”‚   â””â”€â”€ predictor.py         # Prediction interface
â”‚   â””â”€â”€ api/              # REST API
â”‚       â””â”€â”€ app.py               # FastAPI application
â”œâ”€â”€ scripts/              # Executable scripts
â”‚   â”œâ”€â”€ train.py                 # Training script
â”‚   â”œâ”€â”€ inference.py             # Inference script
â”‚   â””â”€â”€ run_api.py               # API server
â”œâ”€â”€ data/                 # Dataset storage
â”œâ”€â”€ models/               # Saved checkpoints
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ main.py               # CLI entry point
â””â”€â”€ pyproject.toml        # Dependencies (uv)
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- CUDA-capable GPU (recommended)
- uv package manager

### Installation

```powershell
# Clone or navigate to the project
cd "c:\Users\DananjayaAbey\Desktop\emotion classification"

# Install dependencies using uv
uv pip install -e .

# For development dependencies
uv pip install -e ".[dev]"
```

### Quick Start

```powershell
# Show system info
python main.py info

# Train a model (after preparing your dataset)
python -m scripts.train --data-dir ./data/train --output-dir ./models --epochs 50

# Run inference on an image
python -m scripts.inference --checkpoint ./models/best_model.pth --image test.jpg --show-scores

# Start API server
python -m scripts.run_api --checkpoint ./models/best_model.pth --port 8000
```

## ğŸ“š Recommended Datasets

### 1. **AffectNet** (Faces)

- 1M+ in-the-wild face images
- 440K with emotion labels (7 discrete + valence/arousal)
- Best for: Portrait/selfie heavy content

### 2. **FI (Flickr & Instagram)**

- ~23K social media images
- 8 emotion categories (Mikels' model)
- Best for: General social media content

### 3. **EmoSet** (ICCV 2023)

- Large-scale visual emotion dataset
- Multiple affective labels
- Best for: Comprehensive emotion coverage

## ğŸ“ Training

### Basic Training

```python
from src.config.model_config import ModelConfig
from src.config.training_config import TrainingConfig
from src.models.emotion_classifier import EmotionClassifier
from src.training.trainer import Trainer

# Configure
model_config = ModelConfig(backbone="vit_base_patch16_224")
training_config = TrainingConfig(
    batch_size=32,
    num_epochs=50,
    learning_rate=1e-4,
)

# Create model
model = EmotionClassifier(model_config)

# Train (after loading data)
# trainer = Trainer(model, train_loader, val_loader, training_config, model_config)
# trainer.train()
```

### Hyperparameters

```python
# Model
- backbone: "vit_base_patch16_224", "resnet50", "efficientnet_b0"
- image_size: 224
- dropout: 0.1

# Training
- batch_size: 32
- learning_rate: 1e-4
- optimizer: AdamW
- scheduler: cosine
- mixed_precision: True
- early_stopping_patience: 10

# Data Augmentation
- horizontal_flip: True
- rotation: 15Â°
- color_jitter: True
```

## ğŸ”® Inference

### Python API

```python
from src.inference.predictor import EmotionPredictor
from pathlib import Path

# Load model
predictor = EmotionPredictor.from_checkpoint(
    Path("models/best_model.pth"),
    device="cuda",
    threshold=0.35
)

# Predict
result = predictor.predict("image.jpg")
print(f"Emotions: {result['predicted_emotions']}")
print(f"Allowed emojis: {result['allowed_emojis']}")
```

### REST API

```powershell
# Start server
python -m scripts.run_api --checkpoint ./models/best_model.pth

# Use API (in another terminal or browser)
# Docs: http://localhost:8000/docs
```

**API Endpoints:**

- `POST /predict` - Full emotion prediction with emojis
- `POST /predict_emojis` - Get only allowed emojis
- `GET /emotions` - List supported emotions
- `GET /emotion_mappings` - Get emotion-emoji mappings
- `GET /health` - Health check

**Example cURL:**

```bash
curl -X POST "http://localhost:8000/predict" \
  -F "file=@image.jpg" \
  -F "include_scores=true"
```

## ğŸ§ª Model Performance

Track these metrics during training:

- **F1 Score** (macro): Primary metric
- **F1 Score** (micro/weighted): For imbalanced data
- **Per-class F1**: Individual emotion performance
- **Precision/Recall**: Fine-grained analysis

## ğŸ› ï¸ Development

### Code Style

```powershell
# Format code
uv run black src/ scripts/ tests/

# Sort imports
uv run isort src/ scripts/ tests/

# Lint
uv run flake8 src/ scripts/ tests/

# Type check
uv run mypy src/
```

### Testing

```powershell
# Run tests
uv run pytest tests/

# With coverage
uv run pytest --cov=src tests/
```

## ğŸ¯ Roadmap

- [ ] Implement dataset loaders for AffectNet, FI, EmoSet
- [ ] Add data preprocessing utilities
- [ ] Create training visualization with TensorBoard/Weights & Biases
- [ ] Implement model export (ONNX/TorchScript)
- [ ] Add batch inference script
- [ ] Create web demo with Gradio/Streamlit
- [ ] Add multi-GPU training support
- [ ] Implement test time augmentation (TTA)
- [ ] Add confidence calibration
- [ ] Create Docker container

## ğŸ“– References

- **AffectNet**: [Mollahosseini et al., 2017](http://mohammadmahoor.com/affectnet/)
- **FI Dataset**: [You et al., 2016](https://github.com/dchen236/FairFace)
- **Vision Transformers**: [Dosovitskiy et al., 2021](https://arxiv.org/abs/2010.11929)
- **timm library**: [Ross Wightman](https://github.com/rwightman/pytorch-image-models)

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests and linting
5. Submit a pull request

## ğŸ“§ Contact

For questions or suggestions, please open an issue.

---

**Built with â¤ï¸ using PyTorch, FastAPI, and modern ML practices**
